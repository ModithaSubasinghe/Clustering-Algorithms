{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder #For encoding categorical variables\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans,AgglomerativeClustering,DBSCAN\n",
    "from sklearn.metrics import accuracy_score,f1_score,adjusted_rand_score,silhouette_score\n",
    "from joblib import Parallel,delayed\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Datasets Using openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "iris = openml.datasets.get_dataset(\"iris\")\n",
    "iris_df, iris_label, categorical_indicator, attribute_names = iris.get_data(\n",
    "    target=iris.default_target_attribute, dataset_format=\"dataframe\"\n",
    ")\n",
    "iris_df[\"class\"]=iris_label\n",
    "iris_x=iris_df.iloc[:,:4]\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "wine = openml.datasets.get_dataset(\"wine\")\n",
    "wine_df, wine_label, categorical_indicator, attribute_names = wine.get_data(\n",
    "    target= wine.default_target_attribute, dataset_format=\"dataframe\"\n",
    ")\n",
    "wine_df[\"class\"]=wine_label\n",
    "wine_x=wine_df.iloc[:,:13]\n",
    "wine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "iris_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "wine_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform categorical variable to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "\n",
    "iris_y=le.fit_transform(iris_label)\n",
    "wine_y=le.fit_transform(wine_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min-max normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "iris_x_scaled=scaler.fit_transform(iris_x)\n",
    "wine_x_scaled=scaler.fit_transform(wine_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "Dataset = [\"Iris\",\"Wine\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def kmeans (x, y, parameters):\n",
    "    start_time = time.time()\n",
    "    kmeans = KMeans(n_clusters = parameters[0], max_iter = parameters[1], n_init = parameters[2])\n",
    "    y_kmeans = kmeans.fit_predict(x)\n",
    "    kmeans_f1score = f1_score(y, y_kmeans, average = 'weighted')\n",
    "    kmeans_ars = adjusted_rand_score(y, y_kmeans)\n",
    "    kmeans_sscore = silhouette_score(x, y_kmeans, metric='euclidean')\n",
    "    kmeans_execution_time = time.time() - start_time\n",
    "    return y_kmeans, kmeans_f1score, kmeans_ars, kmeans_sscore, kmeans_execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "n_clusters=[2,3,4,5,6,7]\n",
    "max_iter=[200,300,400]\n",
    "n_init=[5,10,15]\n",
    "    \n",
    "kmean_parameters = pd.DataFrame({\"n_clusters\":[] , \n",
    "                                 \"max_iter\":[] , \n",
    "                                 \"n_init\":[]}).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in n_clusters:\n",
    "        for  ite in max_iter:\n",
    "            for n in n_init:\n",
    "                kmean_parameters = kmean_parameters.append({\"n_clusters\" : i, \n",
    "                                                            \"max_iter\" : ite, \n",
    "                                                            \"n_init\" : n},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "kmean_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "final_iris_kmeans = Parallel(n_jobs=-1)(delayed(kmeans)(iris_x_scaled, iris_y, kmean_parameters.iloc[i]) for i in range(0, len(kmean_parameters)))\n",
    "final_wine_kmeans = Parallel(n_jobs=-1)(delayed(kmeans)(wine_x_scaled, wine_y, kmean_parameters.iloc[i]) for i in range(0, len(kmean_parameters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "final_kmeans_df=pd.DataFrame({\n",
    "    \"Dataset\":[],\n",
    "    \"n_clusters\":[],\n",
    "    \"max_iter\":[],\n",
    "    \"n_init\":[],\n",
    "    \"f1 score\":[],\n",
    "    \"Adjusted Random Score\":[],\n",
    "    \"Silhouette Score\":[],\n",
    "    \"Execution Time\":[],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(kmean_parameters)):\n",
    "    final_kmeans_df =final_kmeans_df.append({\n",
    "        \"Dataset\":Dataset[0],\n",
    "        \"n_clusters\":kmean_parameters.iloc[i][0],\n",
    "        \"max_iter\":kmean_parameters.iloc[i][1],\n",
    "        \"n_init\":kmean_parameters.iloc[i][2],\n",
    "        \"f1 score\":final_iris_kmeans[i][1],\n",
    "        \"Adjusted Random Score\":final_iris_kmeans[i][2],\n",
    "        \"Silhouette Score\":final_iris_kmeans[i][3],\n",
    "        \"Execution Time\":final_iris_kmeans[i][4],\n",
    "        },ignore_index=True)\n",
    "    \n",
    "for i in range(0, len(kmean_parameters)):\n",
    "    final_kmeans_df =final_kmeans_df.append({\n",
    "        \"Dataset\":Dataset[0],\n",
    "        \"n_clusters\":kmean_parameters.iloc[i][0],\n",
    "        \"max_iter\":kmean_parameters.iloc[i][1],\n",
    "        \"n_init\":kmean_parameters.iloc[i][2],\n",
    "        \"f1 score\":final_wine_kmeans[i][1],\n",
    "        \"Adjusted Random Score\":final_wine_kmeans[i][2],\n",
    "        \"Silhouette Score\":final_wine_kmeans[i][3],\n",
    "        \"Execution Time\":final_wine_kmeans[i][4],\n",
    "        \"Dataset\":Dataset[1]\n",
    "        },ignore_index=True)\n",
    "final_kmeans_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def agglomerative (x, y, parameters):\n",
    "    start_time = time.time()\n",
    "    agglomerative= AgglomerativeClustering(n_clusters = parameters[0], linkage = parameters[1])\n",
    "    y_agglomerative = agglomerative.fit_predict(x)\n",
    "    agglomerative_f1score = f1_score(y, y_agglomerative, average = \"weighted\")\n",
    "    agglomerative_ars = adjusted_rand_score(y, y_agglomerative)\n",
    "    agglomerative_sscore = silhouette_score(x, y_agglomerative, metric=\"euclidean\")\n",
    "    agglomerative_execution_time = time.time() - start_time\n",
    "    return y_agglomerative, agglomerative_f1score,agglomerative_ars, agglomerative_sscore, agglomerative_execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "n_clusters =[2,3,4,5,6,7]\n",
    "linkage = [\"ward\", \"complete\", \"average\", \"single\"]\n",
    "\n",
    "agglomerative_parameters = pd.DataFrame({\n",
    "    \"n_clusters\":[] ,\n",
    "    \"linkage\":[]}).astype(int)\n",
    "  \n",
    "for i in n_clusters:\n",
    "        for  n in linkage:\n",
    "                agglomerative_parameters = agglomerative_parameters.append({\n",
    "                    \"n_clusters\" : i, \n",
    "                    \"linkage\" : n },\n",
    "                    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "agglomerative_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "final_iris_aggromilative = Parallel(n_jobs=-1)(delayed(agglomerative)(iris_x_scaled, iris_y, agglomerative_parameters.iloc[i]) for i in range(0, len(agglomerative_parameters)))\n",
    "final_wine_aggromilative = Parallel(n_jobs=-1)(delayed(agglomerative)(wine_x_scaled, wine_y, agglomerative_parameters.iloc[i]) for i in range(0, len(agglomerative_parameters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "final_aggromilative_df=pd.DataFrame({\n",
    "    \"Dataset\":[],\n",
    "    \"n_clusters\":[],\n",
    "    \"linkage\":[],\n",
    "    \"f1 score\":[],\n",
    "    \"Adjusted Random Score\":[],\n",
    "    \"Silhouette Score\":[],\n",
    "    \"Execution Time\":[],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(agglomerative_parameters)):\n",
    "    final_aggromilative_df =final_aggromilative_df.append({\n",
    "        \"Dataset\":Dataset[0],\n",
    "        \"n_clusters\":agglomerative_parameters.iloc[i][0],\n",
    "        \"linkage\":agglomerative_parameters.iloc[i][1],\n",
    "        \"f1 score\":final_iris_aggromilative[i][1],\n",
    "        \"Adjusted Random Score\":final_iris_aggromilative[i][2],\n",
    "        \"Silhouette Score\":final_iris_aggromilative[i][3],\n",
    "        \"Execution Time\":final_iris_aggromilative[i][4],\n",
    "        },ignore_index=True)\n",
    "    \n",
    "for i in range(0, len(agglomerative_parameters)):\n",
    "    final_aggromilative_df =final_aggromilative_df.append({\n",
    "        \"Dataset\":Dataset[1],\n",
    "        \"n_clusters\":agglomerative_parameters.iloc[i][0],\n",
    "        \"linkage\":agglomerative_parameters.iloc[i][1],\n",
    "        \"f1 score\":final_wine_aggromilative[i][1],\n",
    "        \"Adjusted Random Score\":final_wine_aggromilative[i][2],\n",
    "        \"Silhouette Score\":final_wine_aggromilative[i][3],\n",
    "        \"Execution Time\":final_wine_aggromilative[i][4],\n",
    "        },ignore_index=True)\n",
    "    \n",
    "final_aggromilative_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBScan Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def dbscan (x, y, parameters):\n",
    "    start_time = time.time()\n",
    "    dbscan= DBSCAN(eps = parameters[0], min_samples = parameters[1])\n",
    "    y_dbscan = dbscan.fit_predict(x)\n",
    "    dbscan_f1score = f1_score(y, y_dbscan, average = \"weighted\")\n",
    "    dbscan_ars = adjusted_rand_score(y, y_dbscan)\n",
    "    dbscan_n_clusters = len(set(y_dbscan)) - (1 if -1 in y_dbscan else 0)\n",
    "    if dbscan_n_clusters>=2:\n",
    "        dbscan_sscore = silhouette_score(x, y_dbscan, metric=\"euclidean\")\n",
    "    else:\n",
    "        dbscan_sscore = print(\"111\")\n",
    "    dbscan_execution_time = time.time() - start_time\n",
    "    return y_dbscan, dbscan_f1score,dbscan_ars,dbscan_sscore, dbscan_execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "eps = [0.1,0.2,0.3,0.4,0.5]\n",
    "min_samples = [2,3,4,5,6,7,8]\n",
    "\n",
    "dbscan_parameters = pd.DataFrame({\n",
    "    \"eps\":[],\n",
    "    \"min_samples\" :[]\n",
    "}).astype(int)\n",
    "\n",
    "for i in eps:\n",
    "    for n in min_samples:\n",
    "        dbscan_parameters=dbscan_parameters.append({\n",
    "            \"eps\" : i,\n",
    "            \"min_samples\": n\n",
    "        },ignore_index=True)\n",
    "        \n",
    "dbscan_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "final_iris_dbscan = Parallel(n_jobs=-1)(delayed(dbscan)(iris_x_scaled, iris_y, dbscan_parameters.iloc[i]) for i in range(0, len(dbscan_parameters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "final_dbscan_df=pd.DataFrame({\n",
    "    \"Dataset\":[],\n",
    "    \"eps\":[],\n",
    "    \"min_samples\":[],\n",
    "    \"f1 score\":[],\n",
    "    \"Adjusted Random Score\":[],\n",
    "    \"Silhouette Score\":[],\n",
    "    \"Execution Time\":[],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(dbscan_parameters)):\n",
    "    final_dbscan_df =final_dbscan_df.append({\n",
    "        \"Dataset\":Dataset[0],\n",
    "        \"eps\":dbscan_parameters.iloc[i][0],\n",
    "        \"min_samples\":dbscan_parameters.iloc[i][1],\n",
    "        \"f1 score\":final_iris_dbscan[i][1],\n",
    "        \"Adjusted Random Score\":final_iris_dbscan[i][2],\n",
    "        \"Silhouette Score\":final_iris_dbscan[i][3],\n",
    "        \"Execution Time\":final_iris_dbscan[i][4],\n",
    "        },ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "final_dbscan_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# n_clusters = len(set(y_dbscan)) - (1 if -1 in y_dbscan else 0)\n",
    "# n_noise = list(y_dbscan).count(-1)\n",
    "\n",
    "# print('Estimated number of clusters: %d' % n_clusters)\n",
    "# print('Estimated number of noise points: %d' % n_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike k-means, DBSCAN will figure out the number of clusters. \n",
    "DBSCAN works by determining whether the minimum number of points are close enough to \n",
    "one another to be considered part of a single cluster. DBSCAN is very sensitive to scale since \n",
    "epsilon is a fixed value for the maximum distance between two points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optics Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian mixtures Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affinity propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "# afp = AffinityPropagation(damping=0.9, max_iter=200, convergence_iter=15, copy=True, preference=-5, affinity='euclidean', verbose=False, random_state=None)\n",
    "# y_afp=afp.fit_predict(x_scaled)\n",
    "# y_afp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean-shift "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ward hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "labels_true = [0, 0, 0, 1, 1, 1]\n",
    "labels_pred = [0, 0, 0, 1, 1, 2]\n",
    "metrics.rand_score(labels_true, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}